{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equilibrium Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "import urllib\n",
    "import struct\n",
    "import numpy as np\n",
    "import gzip\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# download data if not available\n",
    "# this part of code is directly taken from Benjamin Scellier s code\n",
    "dir_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "path = dir_path+os.sep+\"mnist.pkl.gz\"\n",
    "\n",
    "# DOWNLOAD MNIST DATASET\n",
    "if not os.path.isfile(path):\n",
    "    origin = ('http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz')\n",
    "    print 'Downloading data from %s' % origin\n",
    "    urllib.urlretrieve(origin, path)\n",
    "\n",
    "# LOAD MNIST DATASET\n",
    "f = gzip.open(path, 'rb')\n",
    "(train_x_values, train_y_values), (valid_x_values, valid_y_values), (test_x_values, test_y_values) = cPickle.load(f)\n",
    "f.close()\n",
    "train_data_size= len(train_y_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this part of code is directly taken from Benjamin Scellier s code\n",
    "# HYPERPARAMETERS FOR A NETWORK WITH 1 HIDDEN LAYER\n",
    "net1 = \"net1\", {\n",
    "\"hidden_sizes\" : [500],\n",
    "\"n_epochs\"     : 20,\n",
    "\"n_it_neg\"     : 20,\n",
    "\"n_it_pos\"     : 4,\n",
    "\"epsilon\"      : np.float32(.5),\n",
    "\"beta\"         : np.float32(.05),\n",
    "\"alphas\"       : [np.float32(.1), np.float32(.05)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rho(s):\n",
    "    return (1./(1.+np.exp(-s)))\n",
    "def clamp(s):\n",
    "    return np.clip(s, 0.,1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(a, nb_class):\n",
    "    one_hot=np.zeros(nb_class, dtype=np.float32)\n",
    "    one_hot[a]=1.\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ep_net(object):\n",
    "    # this function is taken from Benjamn Scellier's code\n",
    "    def save_params(self):\n",
    "        f = file(self.path, 'wb')\n",
    "        biases_values  = self.biases\n",
    "        weights_values = self.weights\n",
    "        to_dump        = biases_values, weights_values, self.hyperparameters, self.training_curves\n",
    "        cPickle.dump(to_dump, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "    def __init__(self, name, hyperparameters=dict()):\n",
    "        self.path=name+\".save\"\n",
    "        # load parameters from hyperparamerters\n",
    "        self.biases, self.weights, self.hyperparameters, self.training_curves = self.__load_params(hyperparameters)\n",
    "        #layer size : input layer has 28*28 neuron, hidden units has 500 neuron and output unit has 10 neurons\n",
    "        layer_sizes = [28*28] + self.hyperparameters[\"hidden_sizes\"] + [10]\n",
    "        index=0\n",
    "        self.x_data= train_x_values[index]\n",
    "        self.train_data_size= len(train_y_values)\n",
    "        self.y= train_y_values\n",
    "        self.y_data= self.y[index]\n",
    "        self.y_data_one_hot = to_one_hot(self.y_data, 10)\n",
    "        \n",
    "        values = [np.zeros((train_data_size, layer_size), dtype=np.float32) for layer_size in layer_sizes[1:]]\n",
    "        #print(self.y_data_one_hot)\n",
    "        \n",
    "        self.layers= [self.x_data]+[value[index] for value in values]\n",
    "        print(layer.shape for layer in self.layers)\n",
    "    def update(self, index):\n",
    "        layer_sizes = [28*28] + self.hyperparameters[\"hidden_sizes\"] + [10]\n",
    "        self.x_data= train_x_values[index]\n",
    "        self.y_data= self.y[index]\n",
    "        self.y_data_one_hot = to_one_hot(self.y_data, 10)\n",
    "        values = [np.zeros((train_data_size, layer_size), dtype=np.float32) for layer_size in layer_sizes[1:]]\n",
    "        self.layers= [self.x_data]+[value[index] for value in values]\n",
    "    def total_energy(self, layers, beta):\n",
    "        return self.energy(layers)+ beta* self.cost(layers)\n",
    "    def cost(self, layers):\n",
    "        outLayer= layers[-1]\n",
    "        originalOutput= self.y_data_one_hot\n",
    "        diff= outLayer- originalOutput\n",
    "        return np.sum(np.multiply(diff, diff))\n",
    "       \n",
    "    def energy(self, layers):\n",
    "        # squared norm sum of 1/2 ui^2\n",
    "        # input layer x, hidden layer h, output layer y\n",
    "        x= layers[0]\n",
    "        h= layers[1]\n",
    "        y= layers[2]\n",
    "        xx= np.sum(np.multiply(clamp(x),clamp(x)))\n",
    "        hh= np.sum(np.multiply(rho(h),rho(h)))\n",
    "        yy= np.sum(np.multiply(rho(y),rho(y)))\n",
    "        #print(\"value of xx\")\n",
    "        #print(h)\n",
    "        squared_norm= xx+yy+hh\n",
    "        #print(squared_norm)\n",
    "        #quadratic term sum Wij rho(ui) rho (uj)\n",
    "        inputWeight= self.weights[0]\n",
    "        hiddenWeight= self.weights[1]\n",
    "        #print(inputWeight.shape)\n",
    "        #print(rho(x).reshape(1,len(x)).shape)\n",
    "        #print(rho(h).shape)\n",
    "        # quadratic term\n",
    "        partA= rho(clamp(x)).reshape(1,len(x))\n",
    "        partB= rho(h).reshape(len(h),1)\n",
    "        partC= np.matmul(partA, inputWeight)\n",
    "        \n",
    "        partD= rho(h).reshape(1, len(h))\n",
    "        partE= rho(y).reshape(len(y),1)\n",
    "        partF= np.matmul(partD, hiddenWeight)\n",
    "        quadratic_term= np.matmul(partC, partB)[0][0]+ np.matmul(partF, partE)[0][0]\n",
    "        #quadratic_term=np.sum(np.matmul(np.matmul(rho(clamp(x)).reshape(1,len(x)),inputWeight),rho(h).reshape(len(h),1)) + np.matmul(np.matmul(rho(h).reshape(1,len(h)), hiddenWeight),rho(y).reshape(len(y),1)))\n",
    "        #print(quadratic_term)\n",
    "        # biased term\n",
    "        inputBias= self.biases[0]\n",
    "        hiddenBias= self.biases[1]\n",
    "        outputBias= self.biases[2]\n",
    "        #print(inputBias.shape)\n",
    "        #print(rho(clamp(x)).shape)\n",
    "        biased_term= np.sum(np.multiply(inputBias, rho(clamp(x))))+np.sum(np.multiply(hiddenBias, rho(h)))+np.sum(np.multiply(outputBias, rho(y)))\n",
    "        \n",
    "        #print(biased_term)\n",
    "        #print(\"energy\")\n",
    "        #print(squared_norm)\n",
    "        #print(quadratic_term.shape)\n",
    "        #print(biased_term)\n",
    "        #print(squared_norm+quadratic_term+biased_term)\n",
    "        return (squared_norm/2.-quadratic_term/2.-biased_term)\n",
    "        \n",
    "    def getEnergyGradient(self, layers, weights, biases):\n",
    "        x= layers[0]\n",
    "        h= layers[1]\n",
    "        y= layers[2]\n",
    "        DE= list()\n",
    "        inputWeight= weights[0]\n",
    "        hiddenWeight= weights[1]\n",
    "        \n",
    "        inputBias= biases[0]\n",
    "        hiddenBias= biases[1]\n",
    "        outputBias= biases[2]\n",
    "        \n",
    "        \n",
    "        #print(\"start grad\")\n",
    "        #print(x.shape)\n",
    "        #print(h.shape)\n",
    "        #print(y.shape)\n",
    "\n",
    "        #calculate dE(x)/dx\n",
    "        \n",
    "        #weighted term\n",
    "        partA= rho(clamp(x))\n",
    "        partA_dot= np.multiply(partA, 1. - partA)\n",
    "        partC= np.matmul(inputWeight, rho(h).reshape(len(h),1))\n",
    "        partD= np.multiply(partA_dot.reshape(len(x),1), partC.reshape(len(x),1))\n",
    "        #biased term\n",
    "        \n",
    "        partE= np.multiply(inputBias.reshape(len(x),1), partA_dot.reshape(len(x),1))\n",
    "        dE_dx= -1*clamp(x).reshape(len(x),1)+ partD/2. + partE\n",
    "        #print(dE_dx.shape)\n",
    "        DE.append(dE_dx)\n",
    "        #calculate  dE/dh\n",
    "        partA= rho(h)\n",
    "        partB= rho(clamp(x))\n",
    "        partC= np.matmul(partB.reshape(1, len(x)), inputWeight)\n",
    "        partD= np.multiply(partA,1.-partA)\n",
    "        partE= np.multiply(partC.reshape(len(h),1), partD.reshape(len(partD),1)) #first w term\n",
    "        \n",
    "        partF= np.matmul(hiddenWeight, rho(y).reshape(len(y),1))\n",
    "        partG= np.multiply(partF, partD.reshape(len(h),1)) # second w term\n",
    "        #biased term\n",
    "        partH= np.multiply(hiddenBias.reshape(len(h),1),partD.reshape(len(h),1) )\n",
    "        \n",
    "        dE_dh= -1*h.reshape(len(h),1) + (partE+partG)/2. + partH\n",
    "        #print(dE_dh.shape)\n",
    "        \n",
    "        DE.append(dE_dh)\n",
    "        \n",
    "        #calculate dE/dy\n",
    "        partA= rho(y)\n",
    "        partB= np.multiply(partA, 1. - partA)\n",
    "        partC= np.matmul(rho(h).reshape(1, len(h)),hiddenWeight)\n",
    "        partD =np.multiply(partC.reshape(len(y),1), partB.reshape(len(y),1))# weighted part\n",
    "        \n",
    "        partE= np.multiply(outputBias.reshape(len(y),1), partB.reshape(len(y),1))\n",
    "        \n",
    "        dE_dy= -1*y.reshape(len(y), 1)+ partD/2. + partE\n",
    "        DE.append(dE_dy)\n",
    "        #print(\"end grad\")\n",
    "        return DE\n",
    "        \n",
    "    def free_phase(self, n_iteration, epsilon, index):\n",
    "        #print(\"in ffre phse\")\n",
    "        layers= self.layers\n",
    "        for i in range(n_iteration):\n",
    "            layers_grad= self.getEnergyGradient(layers, self.weights, self.biases)\n",
    "            layers_new= [layers[0]]+ [layer+epsilon*grad.reshape(len(grad)) for layer, grad in zip(layers, layers_grad)[1:]] \n",
    "            layers= layers_new\n",
    "            \n",
    "\n",
    "        layers_end= [layer[-1] for layer in layers]\n",
    "        \n",
    "        E= self.energy(layers)\n",
    "        C= self.cost(layers)\n",
    "        y_prediction= np.argmax(layers[-1])\n",
    "        error = np.not_equal(y_prediction, self.y_data)*1.\n",
    "\n",
    "        # return the measure E, c and error\n",
    "        return E,C,error, layers\n",
    "    def weakly_clamped_phase(self, n_it_pos, epsilon, beta, alphas, layers):\n",
    "        #print(n_it_pos)\n",
    "        #print(epsilon)\n",
    "        #print(beta)\n",
    "        #print(alphas)\n",
    "        # layer of free phase\n",
    "        \n",
    "        free_phase_layers= layers\n",
    "        for i in range(n_it_pos):\n",
    "            F=self.total_energy(layers, beta)\n",
    "            F_grad= self.getTotalGradient(self.layers, self.weights, self.biases, epsilon, beta, alphas)\n",
    "            layers_new= [layers[0]]+ [layer-epsilon*grad.reshape(len(grad)) for layer, grad in zip(layers, F_grad)[1:]]\n",
    "            layers= layers_new\n",
    "        weakly_clamped_layers= layers\n",
    "        \n",
    "        biases_new= list()\n",
    "        # update the weights and biases\n",
    "        biases_grad= self.getBiasesGrad(free_phase_layers, weakly_clamped_layers)\n",
    "        weights_grad= self.getWeightsGrad(free_phase_layers, weakly_clamped_layers)\n",
    "        biases_new2  = [b - alpha * dot/beta for b,alpha,dot in zip(self.biases[1:],alphas,biases_grad[1:])]\n",
    "        biases_new.append(self.biases[0]-alphas[0]*biases_grad[0]/beta)\n",
    "        biases_new.append(biases_new2[0])\n",
    "        biases_new.append(biases_new2[1])\n",
    "        weights_new = [W - alpha * dot/beta for W,alpha,dot in zip(self.weights,   alphas,weights_grad)]\n",
    "        \n",
    "        #another view\n",
    "        delW= self.getDelW(weakly_clamped_layers, free_phase_layers, beta)\n",
    "        weights_new= [W - alpha * dot for W,alpha,dot in zip(self.weights,   alphas,delW)]\n",
    "        return biases_new, weights_new\n",
    "    \n",
    "    def getDelW(self, wLayer, fLayer, beta):\n",
    "        wIn= wLayer[0]\n",
    "        wHid= wLayer[1]\n",
    "        wOut= wLayer[2]\n",
    "        fIn= fLayer[0]\n",
    "        fHid= fLayer[1]\n",
    "        fOut= fLayer[2]\n",
    "        partA= np.matmul(wIn.reshape(len(wIn),1),wHid.reshape(1, len(wHid)))/beta\n",
    "        partB = np.matmul(wHid.reshape(len(wHid),1),wOut.reshape(1, len(wOut)))/beta\n",
    "        \n",
    "        partC= np.matmul(fIn.reshape(len(fIn),1),fHid.reshape(1, len(fHid)))/beta\n",
    "        partD = np.matmul(fHid.reshape(len(fHid),1),fOut.reshape(1, len(fOut)))/beta\n",
    "        \n",
    "        delW= list()\n",
    "        delW.append(partA-partC)\n",
    "        delW.append(partB-partD)\n",
    "        \n",
    "        \n",
    "        return delW\n",
    "    def getWeightsGrad(self, fLayers,wLayers):\n",
    "        dF_dw=list()\n",
    "        #dF_dw0\n",
    "        partA= rho(clamp(fLayers[0])).reshape(len(fLayers[0]),1)*rho(fLayers[1]).reshape(1, len(fLayers[1]))\n",
    "        partB= rho(clamp(wLayers[0])).reshape(len(wLayers[0]),1)*rho(wLayers[1]).reshape(1, len(wLayers[1]))\n",
    "        \n",
    "        partC= rho(fLayers[1]).reshape(len(fLayers[1]),1)*rho(fLayers[2]).reshape(1, len(fLayers[2]))\n",
    "        partD= rho(wLayers[1]).reshape(len(wLayers[1]),1)*rho(wLayers[2]).reshape(1, len(wLayers[2]))\n",
    "        dF_dw0= (partA-partB)/2.\n",
    "        #print(\"weigths grad\")\n",
    "        dF_dw1= (partC-partD)/2.\n",
    "        #print(dF_dw0.shape)\n",
    "        dF_dw.append(dF_dw0)\n",
    "        dF_dw.append(dF_dw1)\n",
    "        return dF_dw\n",
    "    def getBiasesGrad(self,fLayers, wLayers):\n",
    "        dF_db= list()\n",
    "        inputBias= self.biases[0]\n",
    "        hiddenBias=self.biases[1]\n",
    "        outputBias=self.biases[2]\n",
    "        #dF/db0\n",
    "        dF_db0= rho(clamp(fLayers[0]))-rho(clamp(wLayers[0]))\n",
    "        dF_db1= rho(fLayers[1])-rho(wLayers[1])\n",
    "        dF_db2= rho(fLayers[2])-rho(wLayers[2])\n",
    "        dF_db.append(dF_db0)\n",
    "        dF_db.append(dF_db1)\n",
    "        dF_db.append(dF_db2)\n",
    "        \n",
    "        return dF_db\n",
    "        \n",
    "    def getTotalGradient(self, layers, weights, biases, epsilon, beta, alphas):\n",
    "        DF= self.getEnergyGradient(layers, weights, biases)\n",
    "        #modify last gradient\n",
    "        ll= DF[-1]\n",
    "        #print(\"total grad\")\n",
    "        #print(ll.shape)\n",
    "        y_prediction= layers[-1]\n",
    "        DF[-1]=DF[-1]-2*beta*(self.y_data_one_hot.reshape(len(self.y_data_one_hot),1)-y_prediction.reshape(len(y_prediction),1))\n",
    "        #print(DF[-1].shape)\n",
    "        return DF\n",
    "    def __load_params(self, hyperparameters):\n",
    "        hyper = hyperparameters\n",
    "        # Glorot/Bengio weight initialization\n",
    "        def initialize_layer(n_in, n_out):\n",
    "            rng = np.random.RandomState()\n",
    "            W_values = np.asarray(\n",
    "                rng.uniform(\n",
    "                    low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                    high=np.sqrt(6. / (n_in + n_out)),\n",
    "                    size=(n_in, n_out)\n",
    "                ),\n",
    "                dtype=np.float32\n",
    "            )\n",
    "            return W_values\n",
    "\n",
    "        if os.path.isfile(self.path):\n",
    "            f = file(self.path, 'rb')\n",
    "            biases_values, weights_values, hyperparameters, training_curves = cPickle.load(f)\n",
    "            f.close()\n",
    "            for k,v in hyper.iteritems():\n",
    "                hyperparameters[k]=v\n",
    "        else:\n",
    "            layer_sizes = [28*28] + hyperparameters[\"hidden_sizes\"] + [10]\n",
    "            biases_values  = [np.zeros((size,), dtype=np.float32) for size in layer_sizes]\n",
    "            weights_values = [initialize_layer(size_pre,size_post) for size_pre,size_post in zip(layer_sizes[:-1],layer_sizes[1:])]\n",
    "            training_curves = dict()\n",
    "            training_curves[\"training error\"]   = list()\n",
    "            training_curves[\"validation error\"] = list()\n",
    "\n",
    "        biases  = [value for value in biases_values]\n",
    "        weights = [value for value in weights_values]\n",
    "\n",
    "        return biases, weights, hyperparameters, training_curves\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "def train_model(net):\n",
    "    path         = net.path\n",
    "    hidden_sizes = net.hyperparameters[\"hidden_sizes\"]\n",
    "    n_epochs     = net.hyperparameters[\"n_epochs\"]\n",
    "    n_it_neg     = net.hyperparameters[\"n_it_neg\"]\n",
    "    n_it_pos     = net.hyperparameters[\"n_it_pos\"]\n",
    "    epsilon      = net.hyperparameters[\"epsilon\"]\n",
    "    beta         = net.hyperparameters[\"beta\"]\n",
    "    alphas       = net.hyperparameters[\"alphas\"]\n",
    "    # for each pair of x,y \n",
    "    Err=np.zeros(train_data_size, dtype=np.float32)\n",
    "    for a in range(n_epochs):\n",
    "        print(train_data_size)\n",
    "        for i in range(train_data_size):\n",
    "            #update self.layers\n",
    "            #call free phase\n",
    "            if i%1000==0:\n",
    "                print(\"1000th Milestone\")\n",
    "            E,C,error, layers=net.free_phase(n_it_neg, epsilon, i)\n",
    "            Err[i]= error*100.\n",
    "            # run free phase till settles to a fixed point and collect rho(u0)s \n",
    "            #E,C,error = net.free_phase(n_it_neg, epsilon)\n",
    "            # run weakly clamped phase  and collect rho(ubeta)\n",
    "            \n",
    "            sign = 2*np.random.randint(0,2)-1 # random sign +1 or -1\n",
    "            beta = np.float32(sign*beta) # choose the sign of beta at random\n",
    "            biases_new, weights_new= net.weakly_clamped_phase(n_it_pos, epsilon, beta, alphas, layers)\n",
    "            \n",
    "            # update W\n",
    "            net.biases[0]= biases_new[0]\n",
    "            net.biases[1]=biases_new[1]\n",
    "            net.biases[2]=biases_new[2]\n",
    "            net.weights[0]= weights_new[0]\n",
    "            net.weights[1]= weights_new[1]\n",
    "            \n",
    "            #update layers \n",
    "            if (i<train_data_size-1):\n",
    "                net.update(i+1)\n",
    "        print(\"processed \"+str(i)+\"images\")\n",
    "        print(\"epoch \"+ str(a)+\" completed\")\n",
    "        net.training_curves[\"training error\"].append(np.average(Err))\n",
    "        print(net.training_curves[\"training error\"])\n",
    "    net.save_params()\n",
    "    print(\"training ends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7f3c2c0fdc30>\n",
      "50000\n",
      "1000th Milestone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/backbencher/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/backbencher/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:40: RuntimeWarning: overflow encountered in multiply\n",
      "/home/backbencher/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:208: RuntimeWarning: overflow encountered in divide\n",
      "/home/backbencher/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:212: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 0 completed\n",
      "[90.138]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 1 completed\n",
      "[90.138, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 2 completed\n",
      "[90.138, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 3 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 4 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 5 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 6 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 7 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 8 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 9 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 10 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 11 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 12 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 13 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 14 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 15 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 16 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 17 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 18 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "50000\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "1000th Milestone\n",
      "processed 49999images\n",
      "epoch 19 completed\n",
      "[90.138, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002, 90.136002]\n",
      "training ends\n",
      "   duration=1925.1 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.clock()\n",
    "train_model(ep_net(*net1))\n",
    "duration = (time.clock() - start_time) / 60.\n",
    "print(\"   duration=%.1f min\" % (duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
